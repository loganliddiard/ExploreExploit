import numpy as np
import matplotlib.pyplot as plt

class EpsilonGreedy:
    def __init__(self, n_arms, epsilon):
        self.n_arms = n_arms  # Number of arms (choices)
        self.epsilon = epsilon  # Exploration rate
        self.counts = np.zeros(n_arms)  # Number of times each arm was chosen
        self.values = np.zeros(n_arms)  # Estimated value of each arm

    def select_action(self):
        """Select an arm based on epsilon-greedy strategy."""
        if np.random.random() > self.epsilon:
            # Exploit: choose the arm with the highest estimated value
            return np.argmax(self.values)
        else:
            # Explore: choose a random arm
            return np.random.randint(self.n_arms)

    def update(self, chosen_arm, reward):
        """Update the chosen arm's value with the received reward."""
        self.counts[chosen_arm] += 1
        n = self.counts[chosen_arm]
        value = self.values[chosen_arm]
        # Incremental update to avoid recomputing sum of rewards
        new_value = ((n - 1) / n) * value + (1 / n) * reward
        self.values[chosen_arm] = new_value


def get_probabilities(drift=0):
    probs = [
        np.random.normal(0, 5),
        np.random.normal(-0.5, 12),
        np.random.normal(2, 3.9),
        np.random.normal(-0.5, 7),
        np.random.normal(-1.2, 8),
        np.random.normal(-3, 7),
        np.random.normal(-10, 20),
        np.random.normal(-0.5, 1),
        np.random.normal(-1, 2),
        np.random.normal(1, 6),
        np.random.normal(0.7, 4),
        np.random.normal(-6, 11),
        np.random.normal(-7, 1),
        np.random.normal(-0.5, 2),
        np.random.normal(-6.5, 1),
        np.random.normal(-3, 6),
        np.random.normal(0, 8),
        np.random.normal(2, 3.9),
        np.random.normal(-9, 12),
        np.random.normal(-1, 6),
        np.random.normal(-4.5, 8),
    ]
    return probs


if __name__ == "__main__":

    # Example usage
    n_actions = 20
    epsilon_values = [0.01,0.05,0.1,0.4]  # 10% chance of exploration
    avg_reward = []
    
    steps = 10_000
    eps_idx = 0

    for epsilon in epsilon_values:
        total = 0
        step = 0
        

        avg_reward.append([])
        algo = EpsilonGreedy(n_actions, epsilon)

        # Simulate x steps rounds
        for _ in range(steps):
            action = algo.select_action()
            rewards = get_probabilities()
            reward = rewards[action]
            algo.update(action, reward)

            total += reward
            step += 1
            temp = total / step
            
            avg_reward[eps_idx].append(temp)

        ##increments which epsilon value we are working with
        eps_idx +=1

    y = range(0, steps)

    val = 0
    for i in avg_reward:
        x = i

        plt.plot(y, x,label=epsilon_values[val])
        val+=1

    plt.legend(title='Epsilon Values')

    plt.xlabel('Steps')
    plt.ylabel('Average Reward')
    plt.title('Epsilon Greedy: Average Reward Over Time')
    plt.savefig("Graph_1.png")
    plt.show()

    print("Estimated values of actions:", algo.values)
